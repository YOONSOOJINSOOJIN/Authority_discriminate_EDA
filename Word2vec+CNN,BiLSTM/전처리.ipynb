{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "작가ai_전처리(Ver1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1WDTHorsSAr"
      },
      "source": [
        "# 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzU4qklJGeTq"
      },
      "source": [
        "실험 1번 -> 대회 log_loss:0.4767405709\n",
        "\n",
        "실험 2번 -> 대회 log_loss:0.5166502922\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIyiLQQnkSXB"
      },
      "source": [
        "**실험 1과 2의 차이는 전처리 방법의 차이가 있다.**\n",
        "\n",
        "**두 실험 다 TF-IDF 임베딩과 같은 기본 자연어 모델 사용**\n",
        "\n",
        "\n",
        "1.   실험1\n",
        "\n",
        " : 프랑스어->영어 번역, 특수 문자 제거(이로 빈 list가 나오면 제거), 불용어 제거(이로 빈 list가 나오면 제거), 소문자로 전환\n",
        "\n",
        "2.   실험2\n",
        "\n",
        " : 프랑스어->영어 번역, 특수 문자 제거(이로 빈 list가 나오면 제거), 불용어 제거(이로 빈 list가 나오면 제거), 소문자로 전환, 표제화(단어 길이 1개 이하 삭제)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vt6G_I3H-Cx"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tcu2PYesRLo"
      },
      "source": [
        "import pandas as pd \n",
        "\n",
        "train_dataset = pd.read_csv(\"/content/train.csv\") \n",
        "test_dataset = pd.read_csv(\"/content/test_x.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox54hTurK05a"
      },
      "source": [
        "## 불어->영어로 번역"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ven2T9YSwub"
      },
      "source": [
        "translate_user_dict = {\"_un doigt d'eau de vie_.\":\"a finger of brandy\", \"Oui, j'ai pris un mot pour un autre.\":\"Yes, I took one word for another.\", \"Mais c'est égal.\":\"But it doesn't matter.\", \"Oui, j'ai beaucoup à vous dire, chère amie.\":\"Yes, I have a lot to tell you, dear friend.\", \"parce que nous avons à parler.\":\"because we have to talk.\", \"Pardon, j'ai oublié son nom.\":\"Sorry, I forgot his name.\", \"Il n'est pas du pays\":\"He is not from the country\", \"quelque chose de bête et d'Allemand dans la physionomie.\":\"something stupid and German in the physiognomy.\", \"C'est encore mieux\":\"It's even better\", \"j'ai en tout quarante roubles mais\":\"I have forty rubles in all but\", \"Grace à Dieu\":\"Thanks to God\", \"c'est une si pauvre tête!\":\"that is such a poor head!\", \"c'est un pauvre sire, tout de même\":\"he is a poor sire, all the same\", \"et puis\":\"and then\", \"c'est très\":\"it's very\", \"c'est rassurant au plus haut degré.\":\"that is reassuring to the highest degree.\", \"Elle me soupçonnera toute sa vie\":\"She will suspect me all her life\", \"c'est égal\":\"is equal\", \"L'Evangile... voyez-vous, désormais nous prêcherons ensemble\":\"The Gospel ... see, from now on we will preach together\", \"c'est admis\":\"it is admitted\", \"chère innocente\":\"dear innocent\", \"et à cette chère ingrate\":\"and to this dear ungrateful\", \"c'est un ange\":\"it's an angel\", \"cette pauvre_ auntie\":\"this poor auntie\", \"Cap'n\":\"captain\", \"jawing--v'yages\":\"jawing - travels\", \"a'terwards\":\"afterwards\", \"m'clour\":\"to me\", \"ma'am\":\"madam\", \"Oh, hier il avait tant d'esprit\":\"Oh, yesterday he had so much wit\",\"d'eau de vie_\":\"brandy_\",\n",
        "\"C'est un pense-creux d'ici\":\"It's a reminder of here\",\n",
        "\"Je n'ai rien contre l'Evangile\":\"I have nothing against the Gospel\",\n",
        "\"C'est le meilleur et le plus irascible homme du monde.\":\"He's the best and most irascible man in the world.\", \n",
        "\"_C'est un ange; c'était plus qu'un ange pour moi.\":\"_It's an angel; it was more than an angel to me.\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTH9Y6muT3HQ"
      },
      "source": [
        "keys = list(translate_user_dict.keys()) \n",
        "keys_with_length = [(key, len(key)) for key in keys]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9zMs4ZzT5D8",
        "outputId": "ce138f2e-cdbc-4b6b-9910-f91a25c8e37d"
      },
      "source": [
        "sorted_keys = sorted(keys_with_length, key=lambda x : -x[1]) \n",
        "sorted_keys = [ key[0] for key in sorted_keys] \n",
        "sorted_keys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"L'Evangile... voyez-vous, désormais nous prêcherons ensemble\",\n",
              " \"quelque chose de bête et d'Allemand dans la physionomie.\",\n",
              " \"C'est le meilleur et le plus irascible homme du monde.\",\n",
              " \"_C'est un ange; c'était plus qu'un ange pour moi.\",\n",
              " \"Oui, j'ai beaucoup à vous dire, chère amie.\",\n",
              " \"Oui, j'ai pris un mot pour un autre.\",\n",
              " \"c'est rassurant au plus haut degré.\",\n",
              " \"j'ai en tout quarante roubles mais\",\n",
              " \"c'est un pauvre sire, tout de même\",\n",
              " 'Elle me soupçonnera toute sa vie',\n",
              " \"Oh, hier il avait tant d'esprit\",\n",
              " 'parce que nous avons à parler.',\n",
              " \"Je n'ai rien contre l'Evangile\",\n",
              " \"Pardon, j'ai oublié son nom.\",\n",
              " \"C'est un pense-creux d'ici\",\n",
              " \"c'est une si pauvre tête!\",\n",
              " \"_un doigt d'eau de vie_.\",\n",
              " 'et à cette chère ingrate',\n",
              " \"Il n'est pas du pays\",\n",
              " 'cette pauvre_ auntie',\n",
              " \"C'est encore mieux\",\n",
              " \"Mais c'est égal.\",\n",
              " 'chère innocente',\n",
              " \"jawing--v'yages\",\n",
              " \"c'est un ange\",\n",
              " \"d'eau de vie_\",\n",
              " 'Grace à Dieu',\n",
              " \"c'est admis\",\n",
              " \"c'est très\",\n",
              " \"c'est égal\",\n",
              " \"a'terwards\",\n",
              " 'et puis',\n",
              " \"m'clour\",\n",
              " \"Cap'n\",\n",
              " \"ma'am\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSNb_yPSTiA1",
        "outputId": "84d92da7-c21c-4689-a87d-d6fa30e155d7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "cnt = 0 \n",
        "text_list = list(train_dataset['text']) \n",
        "\n",
        "for i in tqdm(range(len(sorted_keys))): \n",
        "  for j in range(len(text_list)): \n",
        "    if sorted_keys[i] in text_list[j]: \n",
        "      text_list[j] = text_list[j].replace(sorted_keys[i], translate_user_dict[sorted_keys[i]]) \n",
        "      cnt = cnt + 1\n",
        "\n",
        "print(\"{}번 수정되었습니다.\".format(cnt))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 41.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "156번 수정되었습니다.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO6ko6isUJtM",
        "outputId": "f19bec51-eb26-445e-e846-931ff1b33ed6"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "cnt = 0 \n",
        "text_list2 = list(test_dataset['text']) \n",
        "for i in tqdm(range(len(sorted_keys))): \n",
        "  for j in range(len(text_list2)): \n",
        "    if sorted_keys[i] in text_list2[j]: \n",
        "      text_list2[j] = text_list2[j].replace(sorted_keys[i], translate_user_dict[sorted_keys[i]]) \n",
        "      cnt = cnt + 1 \n",
        "print(\"{}번 수정되었습니다.\".format(cnt))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:00<00:00, 84.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "42번 수정되었습니다.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M1hHyJ7Lt0M",
        "outputId": "1cfa4fd0-d625-4fd4-f54b-e9d0d8c79b24"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def show_check_token_string(check_token, check_df): \n",
        "  for i in tqdm(range(len(check_df))): \n",
        "    if check_token in check_df['text'].iloc[i]:\n",
        "       print(check_df['text'].iloc[i])\n",
        "\n",
        "check_token = \"d'eau\" \n",
        "show_check_token_string(check_token=check_token, check_df=train_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54879/54879 [00:00<00:00, 96281.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\"How rich they are and how good! And if one could only have _un doigt d'eau de vie_.\"\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtmrMY7QcAAL",
        "outputId": "b778c821-0141-4594-835c-6129fe7347bf"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDSEfkg0IfrU"
      },
      "source": [
        "## 불용어 baseline 리스트로 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs8tGvnMsDtZ"
      },
      "source": [
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "def remove_stopwords(text):\n",
        "  final_text = []\n",
        "  for i in text.split():\n",
        "    if i.strip().lower() not in stopwords:\n",
        "      final_text.append(i.strip())\n",
        "  return \" \".join(final_text)\n",
        "\n",
        "\n",
        "#불용어 baseline\n",
        "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
        "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
        "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
        "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
        "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
        "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
        "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
        "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
        "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
        "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
        "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYw3xgLGZjgU"
      },
      "source": [
        "train_dataset['clear_text']=text_list\n",
        "test_dataset['clear_text']=text_list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXPxUpwgJbHB"
      },
      "source": [
        "## 소문자로 다 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrnD5BfIsDti"
      },
      "source": [
        "train_dataset['clear_text'] = train_dataset['clear_text'].str.lower().apply(remove_stopwords)\n",
        "test_dataset['clear_text'] = test_dataset['clear_text'].str.lower().apply(remove_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "oY_8GIb2sDtj",
        "outputId": "6a272c7f-e969-4196-bb8a-7663e0b34e0e"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>clear_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>He was almost choking. There was so much, so m...</td>\n",
              "      <td>3</td>\n",
              "      <td>almost choking. much, much wanted say, strange...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>“Your sister asked for it, I suppose?”</td>\n",
              "      <td>2</td>\n",
              "      <td>“your sister asked it, suppose?”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>She was engaged one day as she walked, in per...</td>\n",
              "      <td>1</td>\n",
              "      <td>engaged one day walked, perusing jane’s last l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>The captain was in the porch, keeping himself ...</td>\n",
              "      <td>4</td>\n",
              "      <td>captain porch, keeping carefully way treachero...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>“Have mercy, gentlemen!” odin flung up his han...</td>\n",
              "      <td>3</td>\n",
              "      <td>“have mercy, gentlemen!” odin flung hands. “do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54874</th>\n",
              "      <td>54874</td>\n",
              "      <td>“Is that you, Mr. Smith?” odin whispered. “I h...</td>\n",
              "      <td>2</td>\n",
              "      <td>“is you, mr. smith?” odin whispered. “i hardly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54875</th>\n",
              "      <td>54875</td>\n",
              "      <td>I told my plan to the captain, and between us ...</td>\n",
              "      <td>4</td>\n",
              "      <td>told plan captain, us settled details accompli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54876</th>\n",
              "      <td>54876</td>\n",
              "      <td>\"Your sincere well-wisher, friend, and sister...</td>\n",
              "      <td>1</td>\n",
              "      <td>\"your sincere well-wisher, friend, sister, \"lu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54877</th>\n",
              "      <td>54877</td>\n",
              "      <td>“Then you wanted me to lend you money?”</td>\n",
              "      <td>3</td>\n",
              "      <td>“then wanted lend money?”</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54878</th>\n",
              "      <td>54878</td>\n",
              "      <td>It certainly had not occurred to me before, bu...</td>\n",
              "      <td>0</td>\n",
              "      <td>certainly not occurred before, said, yes, like...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>54879 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  ...                                         clear_text\n",
              "0          0  ...  almost choking. much, much wanted say, strange...\n",
              "1          1  ...                   “your sister asked it, suppose?”\n",
              "2          2  ...  engaged one day walked, perusing jane’s last l...\n",
              "3          3  ...  captain porch, keeping carefully way treachero...\n",
              "4          4  ...  “have mercy, gentlemen!” odin flung hands. “do...\n",
              "...      ...  ...                                                ...\n",
              "54874  54874  ...  “is you, mr. smith?” odin whispered. “i hardly...\n",
              "54875  54875  ...  told plan captain, us settled details accompli...\n",
              "54876  54876  ...  \"your sincere well-wisher, friend, sister, \"lu...\n",
              "54877  54877  ...                          “then wanted lend money?”\n",
              "54878  54878  ...  certainly not occurred before, said, yes, like...\n",
              "\n",
              "[54879 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XELB-HU1IuaF"
      },
      "source": [
        "## 특수문자 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KGnkndK6GM6"
      },
      "source": [
        "#특수 문자 제거\n",
        "from tqdm import tqdm \n",
        "import re \n",
        "list1=[]\n",
        "def get_clean_text_list(data_df):\n",
        "  stemmer = WordNetLemmatizer() #love와 loves 같은 뜻이므로 이런 것을 하나로 통합을 위해서\n",
        "                                #표제어 추출로 기본형으로 바꿔준다\n",
        "  plain_text_list = list(data_df['clear_text']) \n",
        "  clear_text_list = [] \n",
        "  count=0\n",
        "  for i in tqdm(range(len(plain_text_list))): \n",
        "    plain_text = plain_text_list[i] \n",
        "    clear_text = plain_text.replace(\"\\\\\", \"\").replace(\"\\n\", \"\") \n",
        "    clear_text = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'\\“\\”…》]', '', clear_text)\n",
        "    if clear_text.split() == []:\n",
        "        count += 1\n",
        "        list1.append(i)\n",
        "    clear_text_list.append(clear_text.lower()) \n",
        "  print(f\"학습 데이터 중 빈 문장의 갯수 : {count}\")\n",
        "  return clear_text_list\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ_AaAj56TRM",
        "outputId": "1b78e1cb-5c3a-45da-c173-5074478951a5"
      },
      "source": [
        "train_dataset['clear_text'] = get_clean_text_list(train_dataset) \n",
        "test_dataset['clear_text'] = get_clean_text_list(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54879/54879 [00:00<00:00, 142225.79it/s]\n",
            " 46%|████▌     | 8959/19617 [00:00<00:00, 89585.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "학습 데이터 중 빈 문장의 갯수 : 44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19617/19617 [00:00<00:00, 85709.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "학습 데이터 중 빈 문장의 갯수 : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PCL4Pjg8lo39",
        "outputId": "f108fe9e-7340-4e9d-d65f-ee3ada9d8769"
      },
      "source": [
        "print(list1)\n",
        "train_dataset.loc[1455,'clear_text']\n",
        "train_dataset.loc[train_dataset['clear_text']=='    ']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1455, 3493, 5523, 5985, 8400, 9874, 12267, 12460, 13055, 14698, 15958, 18475, 19802, 22532, 23137, 23211, 23829, 24589, 25719, 27424, 27575, 27811, 28023, 28224, 28917, 35594, 35754, 38536, 39121, 40152, 43324, 43464, 43686, 43706, 47345, 47525, 47699, 47783, 49308, 50326, 50343, 50963, 52675, 54750]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "      <th>clear_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>1455</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3493</th>\n",
              "      <td>3493</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5523</th>\n",
              "      <td>5523</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5985</th>\n",
              "      <td>5985</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8400</th>\n",
              "      <td>8400</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9874</th>\n",
              "      <td>9874</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12267</th>\n",
              "      <td>12267</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12460</th>\n",
              "      <td>12460</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13055</th>\n",
              "      <td>13055</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14698</th>\n",
              "      <td>14698</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15958</th>\n",
              "      <td>15958</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18475</th>\n",
              "      <td>18475</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19802</th>\n",
              "      <td>19802</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22532</th>\n",
              "      <td>22532</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23137</th>\n",
              "      <td>23137</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23211</th>\n",
              "      <td>23211</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23829</th>\n",
              "      <td>23829</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24589</th>\n",
              "      <td>24589</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25719</th>\n",
              "      <td>25719</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27424</th>\n",
              "      <td>27424</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27575</th>\n",
              "      <td>27575</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27811</th>\n",
              "      <td>27811</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28023</th>\n",
              "      <td>28023</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28224</th>\n",
              "      <td>28224</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28917</th>\n",
              "      <td>28917</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35594</th>\n",
              "      <td>35594</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35754</th>\n",
              "      <td>35754</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38536</th>\n",
              "      <td>38536</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39121</th>\n",
              "      <td>39121</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40152</th>\n",
              "      <td>40152</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43324</th>\n",
              "      <td>43324</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43464</th>\n",
              "      <td>43464</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43686</th>\n",
              "      <td>43686</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43706</th>\n",
              "      <td>43706</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47345</th>\n",
              "      <td>47345</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47525</th>\n",
              "      <td>47525</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47699</th>\n",
              "      <td>47699</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47783</th>\n",
              "      <td>47783</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49308</th>\n",
              "      <td>49308</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50326</th>\n",
              "      <td>50326</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50343</th>\n",
              "      <td>50343</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50963</th>\n",
              "      <td>50963</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52675</th>\n",
              "      <td>52675</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54750</th>\n",
              "      <td>54750</td>\n",
              "      <td>* * * * *</td>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index        text  author clear_text\n",
              "1455    1455   * * * * *       2           \n",
              "3493    3493   * * * * *       4           \n",
              "5523    5523   * * * * *       4           \n",
              "5985    5985   * * * * *       4           \n",
              "8400    8400   * * * * *       2           \n",
              "9874    9874   * * * * *       3           \n",
              "12267  12267   * * * * *       2           \n",
              "12460  12460   * * * * *       4           \n",
              "13055  13055   * * * * *       4           \n",
              "14698  14698   * * * * *       4           \n",
              "15958  15958   * * * * *       4           \n",
              "18475  18475   * * * * *       4           \n",
              "19802  19802   * * * * *       0           \n",
              "22532  22532   * * * * *       4           \n",
              "23137  23137   * * * * *       4           \n",
              "23211  23211   * * * * *       4           \n",
              "23829  23829   * * * * *       4           \n",
              "24589  24589   * * * * *       4           \n",
              "25719  25719   * * * * *       0           \n",
              "27424  27424   * * * * *       4           \n",
              "27575  27575   * * * * *       4           \n",
              "27811  27811   * * * * *       4           \n",
              "28023  28023   * * * * *       2           \n",
              "28224  28224   * * * * *       4           \n",
              "28917  28917   * * * * *       4           \n",
              "35594  35594   * * * * *       4           \n",
              "35754  35754   * * * * *       4           \n",
              "38536  38536   * * * * *       4           \n",
              "39121  39121   * * * * *       4           \n",
              "40152  40152   * * * * *       2           \n",
              "43324  43324   * * * * *       4           \n",
              "43464  43464   * * * * *       4           \n",
              "43686  43686   * * * * *       2           \n",
              "43706  43706   * * * * *       4           \n",
              "47345  47345   * * * * *       4           \n",
              "47525  47525   * * * * *       4           \n",
              "47699  47699   * * * * *       2           \n",
              "47783  47783   * * * * *       2           \n",
              "49308  49308   * * * * *       4           \n",
              "50326  50326   * * * * *       4           \n",
              "50343  50343   * * * * *       4           \n",
              "50963  50963   * * * * *       2           \n",
              "52675  52675   * * * * *       0           \n",
              "54750  54750   * * * * *       4           "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FnuR2VF87vQ"
      },
      "source": [
        "import numpy as np\n",
        "train_dataset['clear_text'].replace('    ', np.nan, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCFqb5Ryh1-v"
      },
      "source": [
        "train_dataset.dropna(subset=['clear_text'], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYJp2s5oj0Go"
      },
      "source": [
        "train_dataset=train_dataset.reset_index(drop=True)\n",
        "train_dataset=train_dataset.drop(['index'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tVzDpJRp9B9",
        "outputId": "bd10ae55-94bc-4d59-aa22-e7dbc67b2452"
      },
      "source": [
        "import nltk \n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "nltk.download(\"stopwords\") \n",
        "nltk.download(\"punkt\") \n",
        "#불용어 한 번 더 처리 해보기(내장된 기능으로)\n",
        "stopwords_list = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7zMcwZwJiXX"
      },
      "source": [
        "## 내장된 불용어 및 토큰화를 통한 표제화 시도(이 때부터 실험1은 위에 것까지 사용하고 실험2에 이 내용도 포함된다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0fQWPUkt9tx",
        "outputId": "e3e35130-5c1d-42c0-eebe-95dd6ad5b03f"
      },
      "source": [
        "from nltk.tokenize import word_tokenize \n",
        "X_train = []\n",
        "Y_train=[]\n",
        "train_text1=[] \n",
        "train_clear_text = list(train_dataset['clear_text']) \n",
        "stemmer = WordNetLemmatizer() #love와 loves 같은 뜻이므로 이런 것을 하나로 통합을 위해서\n",
        "                                #표제어 추출로 기본형으로 바꿔준다\n",
        "\n",
        "for i in tqdm(range(len(train_clear_text))): \n",
        "  temp = word_tokenize(train_clear_text[i]) \n",
        "  temp = [word for word in temp if word not in stopwords_list]\n",
        "  temp = [stemmer.lemmatize(temps) for temps in temp] #여기에서 표제어 추출하는 이유는 'gentlemen!' 이렇게 붙으면 gentleman!이 아닌 gentlemen!으로 표기함 \n",
        "  temp = [word for word in temp if len(word) > 1]\n",
        "  if temp != []:\n",
        "    wo=temp[0]\n",
        "    for j in range(1,len(temp)):\n",
        "      wo=wo+' '+temp[j]\n",
        "    train_text1.append(wo)\n",
        "    Y_train.append(train_dataset.loc[i,'author'])\n",
        "  X_train.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54835/54835 [00:18<00:00, 2925.66it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWCfB7tHuMOi",
        "outputId": "12f268dd-b886-44a0-8c30-d7087769a464"
      },
      "source": [
        "X_test = [] \n",
        "test_text1=[]\n",
        "test_clear_text = list(test_dataset['clear_text']) \n",
        "stemmer = WordNetLemmatizer() #love와 loves 같은 뜻이므로 이런 것을 하나로 통합을 위해서\n",
        "                                #표제어 추출로 기본형으로 바꿔준다\n",
        "\n",
        "for i in tqdm(range(len(test_clear_text))): \n",
        "  temp = word_tokenize(test_clear_text[i]) \n",
        "  temp = [word for word in temp if word not in stopwords_list] \n",
        "  temp = [stemmer.lemmatize(temps) for temps in temp] #여기에서 표제어 추출하는 이유는 'gentlemen!' 이렇게 붙으면 gentleman!이 아닌 gentlemen!으로 표기함 \n",
        "  temp = [word for word in temp if len(word) > 1]\n",
        "  wo=temp[0]\n",
        "  for j in range(1,len(temp)):\n",
        "    wo=wo+' '+temp[j]\n",
        "  test_text1.append(wo)\n",
        "  X_test.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19617/19617 [00:11<00:00, 1739.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgGOGbN-yxYh",
        "outputId": "7175016f-ea52-4a6a-f5b8-ca148e79ff50"
      },
      "source": [
        "count=0\n",
        "for i in X_test:\n",
        "  if i==[]:\n",
        "    count+=1\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PxdkHgj1YzC",
        "outputId": "53685ce7-a8b4-438d-e5e5-406f09115ede"
      },
      "source": [
        "word_list = [] \n",
        "for i in tqdm(range(len(X_train))): \n",
        "  for j in range(len(X_train[i])): \n",
        "    word_list.append(X_train[i][j]) \n",
        "len(list(set(word_list)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 54835/54835 [00:00<00:00, 210727.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43894"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7R4cv1Z0V8T"
      },
      "source": [
        "Y_train=np.array(Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqZ8dDsi9EaQ"
      },
      "source": [
        "y_train = np.array([x for x in train_dataset['author']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR52_Rb27BYm"
      },
      "source": [
        "# 실험1 : TF-IDF를 통한 Embedding과 기본 모델 적용(실험1의 전처리를 활용) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRW_K8Wa9jw8"
      },
      "source": [
        "train_text = train_dataset.clear_text.tolist()\n",
        "test_text = test_dataset.clear_text.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBR-lack54cW"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range = (1, 2),\n",
        "                        max_features=250000, binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A21dmrQ46-mV",
        "outputId": "a4286a7f-37a6-4eb8-ed76-98c1f240a44d"
      },
      "source": [
        "tfidf.fit(train_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0,\n",
              "                max_features=250000, min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
              "                strip_accents=None, sublinear_tf=True,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7KRJ5PG7Eq9"
      },
      "source": [
        "train_tfidf = tfidf.transform(train_text).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHyy_IyS7pNB"
      },
      "source": [
        "test_tfidf = tfidf.transform(test_text).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMYDoCKb-tU-"
      },
      "source": [
        "label = np.asarray(train_dataset.author)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBzwKGDK2P85"
      },
      "source": [
        "vocab_size=len(list(set(word_list)))\n",
        "embedding_dim = 256\n",
        "max_length = 150\n",
        "padding_type='post'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN8g__vE2P86"
      },
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "#tokenizer에 fit \n",
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhcUhLfxHOJa"
      },
      "source": [
        "# 가벼운 NLP모델 생성\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_dim=250000, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYcWnHB-AkTr",
        "outputId": "3bb471d5-a7ba-4270-db71-79a69366849a"
      },
      "source": [
        "from scipy.sparse import hstack, vstack\n",
        "\n",
        "df_len = train_tfidf.shape[0]\n",
        "pred = []\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001),metrics=['accuracy'])\n",
        "for i in range(10):\n",
        "  model.fit(x = vstack((train_tfidf[:int(df_len/10*(i))], train_tfidf[int(df_len/10*(i+1)):])),\n",
        "            y = np.concatenate([label[:int(df_len/10*(i))], label[int(df_len/10*(i+1)):]], axis = 0),\n",
        "            validation_data = (train_tfidf[int(df_len/10*i):int(df_len/10*(i+1))],label[int(df_len/10*i):int(df_len/10*(i+1))]),\n",
        "            epochs = 4)\n",
        "  proba = model.predict_proba(test_tfidf)\n",
        "  pred.append(proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 1.2028 - accuracy: 0.5363 - val_loss: 0.6080 - val_accuracy: 0.7910\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.3158 - accuracy: 0.9047 - val_loss: 0.5642 - val_accuracy: 0.7974\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 17s 11ms/step - loss: 0.1209 - accuracy: 0.9678 - val_loss: 0.6080 - val_accuracy: 0.7890\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0566 - accuracy: 0.9861 - val_loss: 0.6585 - val_accuracy: 0.7868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 12ms/step - loss: 0.1110 - accuracy: 0.9669 - val_loss: 0.0300 - val_accuracy: 0.9927\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0442 - accuracy: 0.9885 - val_loss: 0.0342 - val_accuracy: 0.9898\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0404 - val_accuracy: 0.9876\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0139 - accuracy: 0.9965 - val_loss: 0.0477 - val_accuracy: 0.9856\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0160 - accuracy: 0.9956 - val_loss: 0.0051 - val_accuracy: 0.9987\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0066 - val_accuracy: 0.9978\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0087 - val_accuracy: 0.9971\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0105 - val_accuracy: 0.9967\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0017 - val_accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0021 - val_accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0019 - val_accuracy: 0.9991\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 0.9985\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9985\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 0.9978\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 0.9993\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0030 - val_accuracy: 0.9989\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0011 - val_accuracy: 0.9995\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0015 - val_accuracy: 0.9993\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0020 - val_accuracy: 0.9993\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 0.0019 - val_accuracy: 0.9991\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0026 - val_accuracy: 0.9989\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 12ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0016 - val_accuracy: 0.9995\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.0021 - val_accuracy: 0.9991\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 0.9991\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 12ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 0.0030 - val_accuracy: 0.9987\n",
            "Epoch 1/4\n",
            "1543/1543 [==============================] - 18s 12ms/step - loss: 0.0017 - accuracy: 0.9993 - val_loss: 6.0267e-04 - val_accuracy: 0.9996\n",
            "Epoch 2/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 6.8112e-04 - val_accuracy: 0.9995\n",
            "Epoch 3/4\n",
            "1543/1543 [==============================] - 18s 12ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 7.9171e-04 - val_accuracy: 0.9995\n",
            "Epoch 4/4\n",
            "1543/1543 [==============================] - 18s 11ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 0.0010 - val_accuracy: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "uadIhRifSKMI",
        "outputId": "952d3879-c049-412f-f8a2-46c1de7c75fe"
      },
      "source": [
        "submission=pd.DataFrame(np.mean(pred, axis = 0))\n",
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.767536</td>\n",
              "      <td>1.292868e-01</td>\n",
              "      <td>1.031040e-01</td>\n",
              "      <td>4.528813e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.036137</td>\n",
              "      <td>0.315264</td>\n",
              "      <td>3.440169e-02</td>\n",
              "      <td>6.615162e-03</td>\n",
              "      <td>6.075814e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.999991</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>1.923541e-06</td>\n",
              "      <td>3.250161e-07</td>\n",
              "      <td>3.886545e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004994</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>9.753662e-01</td>\n",
              "      <td>3.435909e-06</td>\n",
              "      <td>1.963470e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.800370</td>\n",
              "      <td>0.000552</td>\n",
              "      <td>1.956341e-05</td>\n",
              "      <td>1.989727e-01</td>\n",
              "      <td>8.590148e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19612</th>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.999988</td>\n",
              "      <td>6.734959e-09</td>\n",
              "      <td>7.425462e-07</td>\n",
              "      <td>4.758795e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19613</th>\n",
              "      <td>0.891195</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.733312e-04</td>\n",
              "      <td>1.110919e-04</td>\n",
              "      <td>1.084958e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19614</th>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.999969</td>\n",
              "      <td>6.244849e-07</td>\n",
              "      <td>1.349909e-05</td>\n",
              "      <td>3.467702e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19615</th>\n",
              "      <td>0.000109</td>\n",
              "      <td>0.999827</td>\n",
              "      <td>1.642014e-05</td>\n",
              "      <td>4.096863e-05</td>\n",
              "      <td>6.337807e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19616</th>\n",
              "      <td>0.999647</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.028673e-06</td>\n",
              "      <td>2.305070e-04</td>\n",
              "      <td>1.098777e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19617 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1             2             3             4\n",
              "0      0.000028  0.767536  1.292868e-01  1.031040e-01  4.528813e-05\n",
              "1      0.036137  0.315264  3.440169e-02  6.615162e-03  6.075814e-01\n",
              "2      0.999991  0.000003  1.923541e-06  3.250161e-07  3.886545e-06\n",
              "3      0.004994  0.000001  9.753662e-01  3.435909e-06  1.963470e-02\n",
              "4      0.800370  0.000552  1.956341e-05  1.989727e-01  8.590148e-05\n",
              "...         ...       ...           ...           ...           ...\n",
              "19612  0.000011  0.999988  6.734959e-09  7.425462e-07  4.758795e-08\n",
              "19613  0.891195  0.000025  1.733312e-04  1.110919e-04  1.084958e-01\n",
              "19614  0.000017  0.999969  6.244849e-07  1.349909e-05  3.467702e-07\n",
              "19615  0.000109  0.999827  1.642014e-05  4.096863e-05  6.337807e-06\n",
              "19616  0.999647  0.000004  8.028673e-06  2.305070e-04  1.098777e-04\n",
              "\n",
              "[19617 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8aYlkWvSKkt"
      },
      "source": [
        "submission.to_csv('/content/submission.csv', index = False, encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSSTKZ3OKTV7"
      },
      "source": [
        "# 실험2: TF-IDF와 모델 적용(실험2의 전처리를 활용)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Dxnst_SLJw"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer='word', sublinear_tf=True, ngram_range = (1, 2),\n",
        "                        max_features=250000, binary=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD-RcHFSSLJ1",
        "outputId": "0452f5c8-2785-4ffd-e1cf-71fa90b5e143"
      },
      "source": [
        "tfidf.fit(train_text1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0,\n",
              "                max_features=250000, min_df=1, ngram_range=(1, 2), norm='l2',\n",
              "                preprocessor=None, smooth_idf=True, stop_words=None,\n",
              "                strip_accents=None, sublinear_tf=True,\n",
              "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
              "                vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDzNHrpbSLJ4"
      },
      "source": [
        "train_tfidf = tfidf.transform(train_text1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2h4GJCcSLJ5"
      },
      "source": [
        "test_tfidf = tfidf.transform(test_text1).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hagmX5LRSLJ7"
      },
      "source": [
        "vocab_size=len(list(set(word_list)))\n",
        "embedding_dim = 256\n",
        "max_length = 150\n",
        "padding_type='post'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkBRqOPRSLJ7"
      },
      "source": [
        "from keras_preprocessing.text import Tokenizer\n",
        "#tokenizer에 fit \n",
        "tokenizer = Tokenizer(num_words = vocab_size)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size=len(word_index)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgvhP5PaSLJ-"
      },
      "source": [
        "# 가벼운 NLP모델 생성\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, input_dim=250000, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEqYPiuESLJ_",
        "outputId": "9ad27d05-26f1-4d53-d86e-4610a83e43a1"
      },
      "source": [
        "from scipy.sparse import hstack, vstack\n",
        "\n",
        "df_len = train_tfidf.shape[0]\n",
        "pred = []\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001),metrics=['accuracy'])\n",
        "for i in range(10):\n",
        "  model.fit(x = vstack((train_tfidf[:int(df_len/10*(i))], train_tfidf[int(df_len/10*(i+1)):])),\n",
        "            y = np.concatenate([Y_train[:int(df_len/10*(i))], Y_train[int(df_len/10*(i+1)):]], axis = 0),\n",
        "            validation_data = (train_tfidf[int(df_len/10*i):int(df_len/10*(i+1))],Y_train[int(df_len/10*i):int(df_len/10*(i+1))]),\n",
        "            epochs = 4)\n",
        "  print(\"완료\")\n",
        "  proba = model.predict_proba(test_tfidf)\n",
        "  print(\"wo\")\n",
        "  pred.append(proba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 1.2370 - accuracy: 0.5251 - val_loss: 0.6722 - val_accuracy: 0.7614\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.3873 - accuracy: 0.8805 - val_loss: 0.6275 - val_accuracy: 0.7694\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 98s 64ms/step - loss: 0.1735 - accuracy: 0.9493 - val_loss: 0.6572 - val_accuracy: 0.7689\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 100s 65ms/step - loss: 0.0978 - accuracy: 0.9718 - val_loss: 0.7113 - val_accuracy: 0.7616\n",
            "완료\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 102s 66ms/step - loss: 0.1482 - accuracy: 0.9542 - val_loss: 0.0647 - val_accuracy: 0.9812\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 102s 66ms/step - loss: 0.0777 - accuracy: 0.9756 - val_loss: 0.0727 - val_accuracy: 0.9770\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 101s 66ms/step - loss: 0.0519 - accuracy: 0.9832 - val_loss: 0.0835 - val_accuracy: 0.9724\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 101s 65ms/step - loss: 0.0396 - accuracy: 0.9866 - val_loss: 0.0954 - val_accuracy: 0.9692\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0416 - accuracy: 0.9861 - val_loss: 0.0268 - val_accuracy: 0.9890\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 104s 68ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.0316 - val_accuracy: 0.9876\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 103s 67ms/step - loss: 0.0249 - accuracy: 0.9914 - val_loss: 0.0380 - val_accuracy: 0.9854\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 104s 67ms/step - loss: 0.0221 - accuracy: 0.9921 - val_loss: 0.0431 - val_accuracy: 0.9845\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 106s 69ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.0155 - val_accuracy: 0.9949\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 102s 66ms/step - loss: 0.0208 - accuracy: 0.9923 - val_loss: 0.0188 - val_accuracy: 0.9938\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 98s 64ms/step - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.0229 - val_accuracy: 0.9923\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 100s 65ms/step - loss: 0.0182 - accuracy: 0.9928 - val_loss: 0.0260 - val_accuracy: 0.9923\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 98s 64ms/step - loss: 0.0185 - accuracy: 0.9935 - val_loss: 0.0140 - val_accuracy: 0.9938\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 97s 63ms/step - loss: 0.0167 - accuracy: 0.9934 - val_loss: 0.0168 - val_accuracy: 0.9934\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.0194 - val_accuracy: 0.9927\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0150 - accuracy: 0.9938 - val_loss: 0.0223 - val_accuracy: 0.9912\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0161 - accuracy: 0.9934 - val_loss: 0.0120 - val_accuracy: 0.9945\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 98s 63ms/step - loss: 0.0149 - accuracy: 0.9938 - val_loss: 0.0147 - val_accuracy: 0.9936\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 99s 65ms/step - loss: 0.0143 - accuracy: 0.9942 - val_loss: 0.0166 - val_accuracy: 0.9922\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 102s 66ms/step - loss: 0.0135 - accuracy: 0.9943 - val_loss: 0.0183 - val_accuracy: 0.9918\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0145 - accuracy: 0.9939 - val_loss: 0.0107 - val_accuracy: 0.9953\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 100s 65ms/step - loss: 0.0137 - accuracy: 0.9943 - val_loss: 0.0128 - val_accuracy: 0.9943\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.0151 - val_accuracy: 0.9931\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0130 - accuracy: 0.9943 - val_loss: 0.0160 - val_accuracy: 0.9936\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 98s 64ms/step - loss: 0.0134 - accuracy: 0.9945 - val_loss: 0.0121 - val_accuracy: 0.9932\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0128 - accuracy: 0.9946 - val_loss: 0.0140 - val_accuracy: 0.9929\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 97s 63ms/step - loss: 0.0125 - accuracy: 0.9948 - val_loss: 0.0164 - val_accuracy: 0.9920\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 98s 63ms/step - loss: 0.0119 - accuracy: 0.9949 - val_loss: 0.0172 - val_accuracy: 0.9918\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 98s 63ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0137 - val_accuracy: 0.9936\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 97s 63ms/step - loss: 0.0119 - accuracy: 0.9949 - val_loss: 0.0156 - val_accuracy: 0.9932\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0117 - accuracy: 0.9950 - val_loss: 0.0171 - val_accuracy: 0.9925\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 97s 63ms/step - loss: 0.0114 - accuracy: 0.9949 - val_loss: 0.0192 - val_accuracy: 0.9922\n",
            "완료\n",
            "wo\n",
            "Epoch 1/4\n",
            "1541/1541 [==============================] - 98s 64ms/step - loss: 0.0130 - accuracy: 0.9943 - val_loss: 0.0066 - val_accuracy: 0.9967\n",
            "Epoch 2/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0126 - accuracy: 0.9944 - val_loss: 0.0078 - val_accuracy: 0.9962\n",
            "Epoch 3/4\n",
            "1541/1541 [==============================] - 98s 64ms/step - loss: 0.0124 - accuracy: 0.9946 - val_loss: 0.0087 - val_accuracy: 0.9962\n",
            "Epoch 4/4\n",
            "1541/1541 [==============================] - 99s 64ms/step - loss: 0.0121 - accuracy: 0.9945 - val_loss: 0.0094 - val_accuracy: 0.9956\n",
            "완료\n",
            "wo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mmLmJAaASOE"
      },
      "source": [
        "submission1=pd.DataFrame(np.mean(pred, axis = 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "elIK88CI4knK",
        "outputId": "44080401-78ac-4f96-9072-f3f6c0e870d6"
      },
      "source": [
        "submission1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000052</td>\n",
              "      <td>3.009487e-01</td>\n",
              "      <td>1.939046e-02</td>\n",
              "      <td>6.794456e-01</td>\n",
              "      <td>1.628606e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.011434</td>\n",
              "      <td>2.130671e-01</td>\n",
              "      <td>9.957295e-03</td>\n",
              "      <td>7.559936e-01</td>\n",
              "      <td>9.547600e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.999964</td>\n",
              "      <td>5.143142e-06</td>\n",
              "      <td>1.159512e-05</td>\n",
              "      <td>8.397381e-07</td>\n",
              "      <td>1.807547e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002512</td>\n",
              "      <td>7.156198e-07</td>\n",
              "      <td>9.968103e-01</td>\n",
              "      <td>1.344445e-05</td>\n",
              "      <td>6.630187e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.999012</td>\n",
              "      <td>1.092531e-04</td>\n",
              "      <td>6.172190e-05</td>\n",
              "      <td>5.365476e-04</td>\n",
              "      <td>2.809331e-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19612</th>\n",
              "      <td>0.000110</td>\n",
              "      <td>9.998702e-01</td>\n",
              "      <td>4.826353e-07</td>\n",
              "      <td>5.558391e-06</td>\n",
              "      <td>1.335427e-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19613</th>\n",
              "      <td>0.084950</td>\n",
              "      <td>2.646949e-05</td>\n",
              "      <td>4.760989e-05</td>\n",
              "      <td>2.156950e-05</td>\n",
              "      <td>9.149547e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19614</th>\n",
              "      <td>0.000131</td>\n",
              "      <td>9.990660e-01</td>\n",
              "      <td>5.823164e-05</td>\n",
              "      <td>7.438374e-04</td>\n",
              "      <td>5.960819e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19615</th>\n",
              "      <td>0.000344</td>\n",
              "      <td>9.996395e-01</td>\n",
              "      <td>6.079268e-06</td>\n",
              "      <td>4.938213e-06</td>\n",
              "      <td>5.497601e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19616</th>\n",
              "      <td>0.999836</td>\n",
              "      <td>9.942130e-07</td>\n",
              "      <td>3.307827e-06</td>\n",
              "      <td>4.681409e-05</td>\n",
              "      <td>1.129014e-04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19617 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0             1             2             3             4\n",
              "0      0.000052  3.009487e-01  1.939046e-02  6.794456e-01  1.628606e-04\n",
              "1      0.011434  2.130671e-01  9.957295e-03  7.559936e-01  9.547600e-03\n",
              "2      0.999964  5.143142e-06  1.159512e-05  8.397381e-07  1.807547e-05\n",
              "3      0.002512  7.156198e-07  9.968103e-01  1.344445e-05  6.630187e-04\n",
              "4      0.999012  1.092531e-04  6.172190e-05  5.365476e-04  2.809331e-04\n",
              "...         ...           ...           ...           ...           ...\n",
              "19612  0.000110  9.998702e-01  4.826353e-07  5.558391e-06  1.335427e-05\n",
              "19613  0.084950  2.646949e-05  4.760989e-05  2.156950e-05  9.149547e-01\n",
              "19614  0.000131  9.990660e-01  5.823164e-05  7.438374e-04  5.960819e-07\n",
              "19615  0.000344  9.996395e-01  6.079268e-06  4.938213e-06  5.497601e-06\n",
              "19616  0.999836  9.942130e-07  3.307827e-06  4.681409e-05  1.129014e-04\n",
              "\n",
              "[19617 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    }
  ]
}